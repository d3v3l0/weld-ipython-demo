{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weld Demo\n",
    "\n",
    "In this notebook, we will explore implementing a very simple vector library similar to NumPy using Weld. Weld is\n",
    "a API and runtime for accelerating data parallel computations. Weld is particularly useful when computations are composed of smaller functions in a library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Example\n",
    "\n",
    "Let's start with a simple NumPy example. We will write a function which adds an integer to a vector many times. Seems pretty simple! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import os\n",
    "os.environ[\"WELD_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global constants\n",
    "SIZE = (2 << 28)\n",
    "ITERATIONS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_numpy_addition(a):\n",
    "    for i in xrange(ITERATIONS):\n",
    "        a += i\n",
    "    print \"Result:\", a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 418759311360\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((SIZE), dtype='int32')\n",
    "run_numpy_addition(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you can see, that took a rather long time to return a result. Why is that? Most libraries have highly optimized\n",
    "_individual functions_; composing these fast operators in a larger pipeline can often lead to surprisingly long execution times!\n",
    "\n",
    "The above program is slow because significant time is spent scanning through `a` and adding a single number\n",
    "to every element in the array. In other words, the CPU is actually spending most of its time doing memory I/O as opposed to actual arithmetic operations.\n",
    "\n",
    "This is where Weld comes in! By looking at the entire computation at once, Weld can optimize across _all the operations in a program_ rather than each _individual operation_. In workloads like the above, where\n",
    "the operations themselves are not particularly compute-heavy, these kinds of optimizations become very important.\n",
    "\n",
    "### Implementing a Weld-enabled Vector Library\n",
    "\n",
    "We will start this notebook by implementing our very own vector library with Weld. Our library will only support integers and two operations: _summing a vector_ and _adding an integer to each element in a vector_. This should be enough for us to \"Weld-ify\" the above example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from weld.weldobject import *\n",
    "from weld.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## `HelloWeldVector`\n",
    "\n",
    "We will call our class `HelloWeldVector`, which will wrap a NumPy array (we will use NumPy to manage memory) and build up a Weld computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HelloWeldVector(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Initialization\n",
    "\n",
    "Now, let's define some methods on this class. First, `__init__` to create an instance. A few things to note here:\n",
    "\n",
    "1. We take as input an initial vector (this will be a NumPy array with `dtype=\"int32\"`)\n",
    "2. We initialize a `WeldObject`, which manages the data passed into the Weld runtime as well as the computation that will be eventually executed. More on the `_encoder` and `_decoder` later.\n",
    "3. We get a `name` for the current state. Names are basically strings which identify a if a computation currently exists. The current computation is just a single vector of integers; the `weldobj.update` function registers this fact and returns a name.\n",
    "4. Set the code to `name`; the `weld_code` is the actual program Weld executes. Again, this is just returning the input vector for now.\n",
    "\n",
    "That was a lot of stuff! But we're making great progress!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init__(self, vector):\n",
    "    self.vector = vector\n",
    "    self.weldobj = WeldObject(_encoder, _decoder)\n",
    "    name = self.weldobj.update(vector, WeldVec(WeldInt()))\n",
    "    self.weldobj.weld_code = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Elementwise `add` operator\n",
    "\n",
    "We will now add an `add` operator. This takes our vector and adds the passed in `number` to each element. The Weld Intermediate Language looks similar to a typical functional programming language where we might do something like the following to add a number `n` to each element of a vector `v`:\n",
    "\n",
    "```\n",
    "map(v, |x| x + n)\n",
    "```\n",
    "\n",
    "The equivalent Weld program is similar. Weld programs are currently registered as strings, so we do some Python magic to splice in `number` into our string; the vector we operate on is similarly spliced in.\n",
    "\n",
    "Note that the vector we operate over is the current value of `self.weldobj.weld_code`; this implies that we are running the `map` over what the current computation would return! We then assign this program to `self.weldobj.weld_code`, effectively updating the current computation.\n",
    "\n",
    "Implementing the `__iadd__` function allows us to override the `+=` operator in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add(self, number):\n",
    "    template = \"map({0}, |e| e + {1})\"\n",
    "    self.weldobj.weld_code = template.format(\n",
    "        self.weldobj.weld_code, str(number))\n",
    "    return self\n",
    "\n",
    "def __iadd__(self, other):\n",
    "    return self.add(other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Implementing Vector Sum\n",
    "\n",
    "Almost there! Now lets do the vector sum. Like before, we start with a template. The template looks a bit intimidating compared to our `map` function from before, but don't fret! If you look closely, all we're doing is running a `for` loop over some data.\n",
    "\n",
    "The `merger`, `result`, and `merge` functions are operations over _builders_, which are special types in Weld used to capture parallelism. We won't go into much detail here, but basically the `merger[i64,+]` is doing a reduce on each element of the vector where the reduction function is `+`.\n",
    "\n",
    "#### Materialization\n",
    "\n",
    "The vector sum will return a single integer, but our class represents a vector! We can resolve this by _materializing a result_ in this function (_i.e.,_ actually evaluating the computation we've built up). In a fuller library, we wouldn't need to this here and we could track information about what type of object the current computation represents, but we won't do that here.\n",
    "\n",
    "To evaluate an object, we simply call the `evaluate` method. We'll look at the encoders and decoders in the code below soon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vector_sum(self):\n",
    "    template = \"result(for({0}, merger[i64,+], |b,i,e| merge(b, i64(e))))\"\n",
    "    prev_code = self.weldobj.weld_code\n",
    "    self.weldobj.weld_code = template.format(self.weldobj.weld_code)\n",
    "    self.weldobj.decoder = ScalarDecoder()\n",
    "    result = self.weldobj.evaluate(WeldLong(), verbose=False)\n",
    "    self.weldobj.decoder = _decoder\n",
    "    self.weldobj.weld_code = prev_code\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ignore this stuff! Just some Python hackery to add the above functions as methods..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__init__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f3ee70b47002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHelloWeldVector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__init__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHelloWeldVector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHelloWeldVector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__iadd__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHelloWeldVector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__init__' is not defined"
     ]
    }
   ],
   "source": [
    "setattr(HelloWeldVector, '__init__', classmethod(__init__))\n",
    "setattr(HelloWeldVector, 'add', add)\n",
    "setattr(HelloWeldVector, '__iadd__', __iadd__)\n",
    "setattr(HelloWeldVector, 'sum', sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Encoders and Decoders\n",
    "\n",
    "We saw several references to _encoders_ and _decoders_ above. What are those? Weld operates over its own internal data format; we need some way to tell Weld how to map data in Python (or in our case, NumPy) to a data format Weld can understand.\n",
    "\n",
    "That's where encoders and decoders come in! An encoder takes data that will be passed into Weld and marshalls it into a Weld format. A decoder takes data returned by Weld and marshalls it into a format Python understands. _Often, but not always_, marshalling can be done with a simple pointer (instead of data) copy.\n",
    "\n",
    "#### NumPy Encoders and Decoders\n",
    "\n",
    "Weld declares an interface for writing encoders and decoders. Fortunately, since we are working with NumPy, encoders and decoders for NumPy arrays are already built into Weld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from weld.encoders import NumpyArrayEncoder, NumpyArrayDecoder, ScalarDecoder\n",
    "\n",
    "_encoder = NumpyArrayEncoder()\n",
    "_decoder = NumpyArrayDecoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Accelerating our Workload\n",
    "\n",
    "We now have all the pieces we need! Let's copy our NumPy function from above, but make one modification; we'll wrap the NumPy array in a `HelloWeldVector`. We've tried our best to emulate NumPy's API, so the rest of the code looks the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_numpy_addition_with_weld(a):\n",
    "    a = HelloWeldVector(a)\n",
    "    for i in xrange(ITERATIONS):\n",
    "        a += i\n",
    "        \n",
    "    print \"Result:\", a.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function will time and compare the native NumPy function to the Weld function we just implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_against_numpy():\n",
    "    a = np.zeros((SIZE), dtype='int32')\n",
    "\n",
    "    start = time.time()\n",
    "    run_numpy_addition(a)\n",
    "    end = time.time()\n",
    "\n",
    "    numpy_time = end - start\n",
    "\n",
    "    # Because caches are funny things\n",
    "    a = np.zeros((SIZE), dtype='int32')\n",
    "\n",
    "    start = time.time()\n",
    "    run_numpy_addition_with_weld(a)\n",
    "    end = time.time()\n",
    "\n",
    "    run_time = end - start\n",
    "\n",
    "    print \"Speedup:\", numpy_time / run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 418759311360\n",
      "Result: 418759311360\n",
      "Speedup: 7.4842164901\n"
     ]
    }
   ],
   "source": [
    "compare_against_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! By combining each operation into a single loop, we saw a > 5x speedup in performance!\n",
    "\n",
    "Now, let's set the following environment variable, which will increase the _number of threads_ Weld is allowed to use. Because Weld is a _parallel language_, any loop we write in it can be automatically parallelized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 418759311360\n",
      "Result: 418759311360\n",
      "Speedup: 9.60425773098\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WELD_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "compare_against_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!\n",
    "\n",
    "Note that the current version of Weld we're running is actually _missing_ many features discussed in the Weld paper. Namely:\n",
    " \n",
    " * Many optimizations are missing (e.g., common subexpression elimination, constant folding)\n",
    " * No vectorization\n",
    " \n",
    "While some optimizations will be handled by LLVM, things like vectorization (coming soon!) can give even further speedups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Grizzly and Real Workloads\n",
    "\n",
    "The workload we looked at above is actually quite simple, so maybe you're not yet impressed with the speedups Weld generated! We hear you! Grizzly is a subset of Pandas that we integrated with Weld. Grizzly allows us to port Pandas workloads over to use Weld, without changing the application!\n",
    "\n",
    "Let's take Grizzly out for a spin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import Pandas and Grizzly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import grizzly.grizzly as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's write a function that loads some data. Note that Grizzly still depends on native Pandas for I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_cleaning_data():\n",
    "    na_values = ['NO CLUE', 'N/A', '0']\n",
    "    requests = pd.read_csv('data/311-service-requests.csv', na_values=na_values, dtype={'Incident Zip': str})\n",
    "    return requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded data in our CSV to a Pandas dataframe, it's time to play! The dataset we just loaded contains a bunch of zipcodes. But like most data our in the wild, it's noisy! :( Let's use Pandas to clean the data!\n",
    "\n",
    "Some of the zipcodes contain more than 5 digits, so we're going to truncate every zipcode to its first 5 digits. In addition, some of the zipcodes are all-zero -- we're going to convert all those zipcodes to `nan`s. After these cleaning operations, we're going to print the unique zipcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_cleaning_pandas(requests):\n",
    "    requests['Incident Zip'] = requests['Incident Zip'].str.slice(0, 5)\n",
    "    \n",
    "    # Fix requests with 00000 zipcodes\n",
    "    zero_zips = requests['Incident Zip'] == '00000'\n",
    "    requests['Incident Zip'][zero_zips] = np.nan\n",
    "    \n",
    "    # Display unique zip codes.\n",
    "    print 'Result:', requests['Incident Zip'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That wasn't too hard!\n",
    "\n",
    "Now, let's write the same function using Grizzly! Grizzly shares the same API as Pandas, so we're only going to have to wrap the input dataframe in Grizzly's `DataFrameWeld` and we're off to the races!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_cleaning_grizzly(requests):\n",
    "    requests = gr.DataFrameWeld(requests)\n",
    "    requests['Incident Zip'] = requests['Incident Zip'].str.slice(0, 5)\n",
    "    \n",
    "    # Fix requests with 00000 zipcodes\n",
    "    zero_zips = requests['Incident Zip'] == '00000'\n",
    "    requests['Incident Zip'][zero_zips] = 'nan'\n",
    "    \n",
    "    # Display unique zip codes.\n",
    "    print 'Result:', requests['Incident Zip'].unique().evaluate(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load our data, and call the native Pandas function,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_orig = get_data_cleaning_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: ['11432' '11378' '10032' '10023' '10027' '11372' '11419' '11417' '10011'\n",
      " '11225' '11218' '10003' '10029' '10466' '11219' '10025' '10310' '11236'\n",
      " '10033' '11216' '10016' '10305' '10312' '10026' '10309' '10036' '11433'\n",
      " '11235' '11213' '11379' '11101' '10014' '11231' '11234' '10457' '10459'\n",
      " '10465' '11207' '10002' '10034' '11233' '10453' '10456' '10469' '11374'\n",
      " '11221' '11421' '11215' '10007' '10019' '11205' '11418' '11369' '11249'\n",
      " '10005' '10009' '11211' '11412' '10458' '11229' '10065' '10030' '11222'\n",
      " '10024' '10013' '11420' '11365' '10012' '11214' '11212' '10022' '11232'\n",
      " '11040' '11226' '10281' '11102' '11208' '10001' '10472' '11414' '11223'\n",
      " '10040' '11220' '11373' '11203' '11691' '11356' '10017' '10452' '10280'\n",
      " '11217' '10031' '11201' '11358' '10128' '11423' '10039' '10010' '11209'\n",
      " '10021' '10037' '11413' '11375' '11238' '10473' '11103' '11354' '11361'\n",
      " '11106' '11385' '10463' '10467' '11204' '11237' '11377' '11364' '11434'\n",
      " '11435' '11210' '11228' '11368' '11694' '10464' '11415' '10314' '10301'\n",
      " '10018' '10038' '11105' '11230' '10468' '11104' '10471' '11416' '10075'\n",
      " '11422' '11355' '10028' '10462' '10306' '10461' '11224' '11429' '10035'\n",
      " '11366' '11362' '11206' '10460' '10304' '11360' '11411' '10455' '10475'\n",
      " '10069' '10303' '10308' '10302' '11357' '10470' '11367' '11370' '10454'\n",
      " '10451' '11436' '11426' '10153' '11004' '11428' '11427' '11001' '11363'\n",
      " '10004' '10474' '11430' '10000' '10307' '11239' '10119' '10006' '10048'\n",
      " '11697' '11692' '11693' '10573' '00083' nan '11559' '10020' '77056'\n",
      " '11776' '70711' '10282' '11109' '10044' '02061' '77092' '14225' '55164'\n",
      " '19711' '07306' '90010' '11747' '23541' '11788' '07604' '10112' '11563'\n",
      " '11580' '07087' '11042' '07093' '11501' '92123' '11575' '07109' '11797'\n",
      " '10803' '11716' '11722' '11549' '10162' '23502' '11518' '07020' '08807'\n",
      " '11577' '07114' '11003' '07201' '61702' '10103' '29616' '35209' '11520'\n",
      " '11735' '10129' '11005' '41042' '11590' '06901' '07208' '11530' '13221'\n",
      " '10954' '11111' '10107']\n",
      "Total time taken: 124.218\n"
     ]
    }
   ],
   "source": [
    "requests = requests_orig.copy()\n",
    "\n",
    "start = time.time()\n",
    "run_data_cleaning_pandas(requests)\n",
    "end = time.time()\n",
    "print \"Total time taken: %.3f\" % (end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same thing with Grizzly now. First, let's run Grizzly using just the one thread,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WELD_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "requests = requests_orig.copy()\n",
    "\n",
    "start = time.time()\n",
    "run_data_cleaning_grizzly(requests)\n",
    "end = time.time()\n",
    "print \"Total time taken: %.3f\" % (end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's kinda cool!\n",
    "\n",
    "What if we increase the number of threads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WELD_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "start = time.time()\n",
    "run_data_cleaning_grizzly(requests)\n",
    "end = time.time()\n",
    "print \"Total time taken: %.3f\" % (end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad at all!\n",
    "\n",
    "With almost zero change to the application, we were able to get a 5x speedup! [fix this number]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
