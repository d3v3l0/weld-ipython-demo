{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weld Demo\n",
    "\n",
    "Weld is an API and runtime for accelerating data parallel computations. Weld is particularly useful when computations are composed of smaller functions in a library. In this notebook, we will explore implementing a simple vector library similar to NumPy using Weld."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Example\n",
    "\n",
    "Let's start with a simple NumPy example. We will write a function which adds an integer to a vector many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import os\n",
    "os.environ[\"WELD_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global constants\n",
    "\n",
    "# 500m elements = 2GB data\n",
    "SIZE = (2 << 28)\n",
    "ITERATIONS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_numpy_addition(a):\n",
    "    for i in xrange(ITERATIONS):\n",
    "        a += i\n",
    "    return a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 418759311360 (10.57903409 seconds)\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((SIZE), dtype='int32')\n",
    "start = time.time()\n",
    "result = run_numpy_addition(a)\n",
    "end = time.time()\n",
    "print \"Result:\", result, \"({} seconds)\".format(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, that took a rather long time to return a result. Why is that? Most libraries have highly optimized\n",
    "_individual functions_; composing these fast operators in a larger pipeline can often lead to surprisingly long execution times!\n",
    "\n",
    "Now lets try running the same function, but with a Weld-enabled vector implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helloweldvec.vec as wv\n",
    "\n",
    "def run_numpy_addition_weld_builtin(a):\n",
    "    for i in xrange(ITERATIONS):\n",
    "        a += i\n",
    "    return a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 418759311360 (0.692294120789 seconds)\n"
     ]
    }
   ],
   "source": [
    "a = wv.HelloWeldVector(np.zeros((SIZE), dtype='int32'))\n",
    "start = time.time()\n",
    "result = run_numpy_addition_weld_builtin(a)\n",
    "end = time.time()\n",
    "print \"Result:\", result,\"({} seconds)\".format(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That was a lot faster. What changed?\n",
    "\n",
    "The NumPy program is slow because significant time is spent scanning through `a` and adding a single number\n",
    "to every element in the array. In other words, the CPU is actually spending most of its time doing memory I/O as opposed to actual arithmetic operations.\n",
    "\n",
    "This is where Weld comes in. By looking at the entire computation at once, Weld can optimize across _all the operations in a program_ rather than each _individual operation_. In workloads like the above, where\n",
    "the operations themselves are not particularly compute-heavy, these kinds of optimizations become very important.\n",
    "\n",
    "### Implementing a Weld-enabled Vector Library\n",
    "\n",
    "We now implement our very own vector library with Weld. Our library will only support integers and two operations: _summing a vector_ and _adding an integer to each element in a vector_. This should be enough for us to \"Weld-ify\" the NumPy example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from weld.weldobject import *\n",
    "from weld.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## `HelloWeldVector`\n",
    "\n",
    "We will call our class `HelloWeldVector`, which will wrap a NumPy array (we will use NumPy to manage memory) and build up a Weld computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HelloWeldVector(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Initialization\n",
    "\n",
    "Now, let's define some methods on this class. First, `__init__` to create an instance. A few things to note here:\n",
    "\n",
    "1. We take as input an initial vector (this will be a NumPy array with `dtype=\"int32\"`)\n",
    "2. We initialize a `WeldObject`, which manages the data passed into the Weld runtime as well as the computation that will be eventually executed. More on the `_encoder` and `_decoder` later.\n",
    "3. We get a `name` for the current state. Names are basically strings which identify a if a computation currently exists. The current computation is just a single vector of integers; the `weldobj.update` function registers this fact and returns a name.\n",
    "4. Set the code to `name`; the `weld_code` is the actual program Weld executes. Again, this is just returning the input vector for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init__(self, vector):\n",
    "    self.vector = vector\n",
    "    self.weldobj = WeldObject(_encoder, _decoder)\n",
    "    name = self.weldobj.update(vector, WeldVec(WeldInt()))\n",
    "    self.weldobj.weld_code = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Elementwise `add` operator\n",
    "\n",
    "We will now add an `add` operator. This takes our vector and adds the passed in `number` to each element. The Weld Intermediate Language looks similar to a typical functional programming language where we might do something like the following to add a number `n` to each element of a vector `v`:\n",
    "\n",
    "```\n",
    "map(v, |x| x + n)\n",
    "```\n",
    "\n",
    "The equivalent Weld program is similar. Weld programs are currently registered as strings, so we do some Python magic to splice in `number` into our string; the vector we operate on is similarly spliced in.\n",
    "\n",
    "Note that the vector we operate over is the current value of `self.weldobj.weld_code`; this implies that we are running the `map` over what the current computation would return! We then assign this program to `self.weldobj.weld_code`, effectively updating the current computation.\n",
    "\n",
    "Implementing the `__iadd__` function allows us to override the `+=` operator in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add(self, number):\n",
    "    template = \"map({0}, |e| e + {1})\"\n",
    "    self.weldobj.weld_code = template.format(\n",
    "        self.weldobj.weld_code, str(number))\n",
    "    return self\n",
    "\n",
    "def __iadd__(self, other):\n",
    "    return self.add(other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Implementing Vector Sum\n",
    "\n",
    "Almost there! Now lets do the vector sum. Like before, we start with a template. The template looks a bit intimidating compared to our `map` function from before, but don't fret; if you look closely, all we're doing is running a `for` loop over some data.\n",
    "\n",
    "The `merger`, `result`, and `merge` functions are operations over _builders_, which are special types in Weld used to capture parallelism. We won't go into much detail here, but basically the `merger[i64,+]` is doing a reduce on each element of the vector where the reduction function is `+`.\n",
    "\n",
    "#### Materialization\n",
    "\n",
    "The vector sum will return a single integer, but our class represents a vector. We can resolve this by _materializing a result_ in this function (_i.e.,_ actually evaluating the computation we've built up). In a complete library, we wouldn't need to this here and we could track information about what type of object the current computation represents.\n",
    "\n",
    "To evaluate an object, we simply call the `evaluate` method. We'll look at the encoders and decoders in the code below soon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vector_sum(self):\n",
    "    template = \"result(for({0}, merger[i64,+], |b,i,e| merge(b, i64(e))))\"\n",
    "    prev_code = self.weldobj.weld_code\n",
    "    self.weldobj.weld_code = template.format(self.weldobj.weld_code)\n",
    "    self.weldobj.decoder = ScalarDecoder()\n",
    "    result = self.weldobj.evaluate(WeldLong(), verbose=False)\n",
    "    self.weldobj.decoder = _decoder\n",
    "    self.weldobj.weld_code = prev_code\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ignore this stuff! Just some Python hackery to add the above functions as methods..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setattr(HelloWeldVector, '__init__', classmethod(__init__))\n",
    "setattr(HelloWeldVector, 'add', add)\n",
    "setattr(HelloWeldVector, '__iadd__', __iadd__)\n",
    "setattr(HelloWeldVector, 'vector_sum', vector_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Encoders and Decoders\n",
    "\n",
    "We saw several references to _encoders_ and _decoders_ above. What are those? Weld operates over its own internal data format; we need some way to tell Weld how to map data in Python (or in our case, NumPy) to a data format Weld can understand.\n",
    "\n",
    "That's where encoders and decoders come in! An encoder takes data that will be passed into Weld and marshalls it into a Weld format. A decoder takes data returned by Weld and marshalls it into a format Python understands. _Often, but not always_, marshalling can be done with a simple pointer (instead of data) copy.\n",
    "\n",
    "#### NumPy Encoders and Decoders\n",
    "\n",
    "Weld declares an interface for writing encoders and decoders. Fortunately, since we are working with NumPy, encoders and decoders for NumPy arrays are already built into Weld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from weld.encoders import NumpyArrayEncoder, NumpyArrayDecoder, ScalarDecoder\n",
    "\n",
    "_encoder = NumpyArrayEncoder()\n",
    "_decoder = NumpyArrayDecoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Accelerating our Workload\n",
    "\n",
    "We now have all the pieces we need! Let's copy our NumPy function from above, but make one modification; we'll wrap the NumPy array in a `HelloWeldVector`. We've tried our best to emulate NumPy's API, so the rest of the code looks the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_numpy_addition_with_weld(a):\n",
    "    a = HelloWeldVector(a)\n",
    "    for i in xrange(ITERATIONS):\n",
    "        a += i\n",
    "    return a.vector_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function will time and compare the native NumPy function to the Weld function we just implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_against_numpy():\n",
    "    a = np.zeros((SIZE), dtype='int32')\n",
    "\n",
    "    start = time.time()\n",
    "    result_numpy = run_numpy_addition(a)\n",
    "    end = time.time()\n",
    "    print \"NumPy Result:\", result_numpy\n",
    "\n",
    "    numpy_time = end - start\n",
    "\n",
    "    # Because caches are funny things\n",
    "    a = np.zeros((SIZE), dtype='int32')\n",
    "\n",
    "    start = time.time()\n",
    "    result_weld = run_numpy_addition_with_weld(a)\n",
    "    end = time.time()\n",
    "    print \"Weld Result:\", result_weld\n",
    "\n",
    "    run_time = end - start\n",
    "\n",
    "    print \"Speedup:\", numpy_time / run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Result: 418759311360\n",
      "Weld Result: 418759311360\n",
      "Speedup: 15.2814693574\n"
     ]
    }
   ],
   "source": [
    "compare_against_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! By combining each operation into a single loop, we saw a > 5x speedup in performance!\n",
    "\n",
    "Now, let's set the following environment variable, which will increase the _number of threads_ Weld is allowed to use. Because Weld is a _parallel language_, any loop we write in it can be automatically parallelized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Result: 418759311360\n",
      "Weld Result: 418759311360\n",
      "Speedup: 25.7177375091\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WELD_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "compare_against_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!\n",
    "\n",
    "Note that the current version of Weld we're running is actually _missing_ many features discussed in the Weld paper. Namely:\n",
    " \n",
    " * Many optimizations are missing (e.g., common subexpression elimination, constant folding)\n",
    " * No vectorization\n",
    " \n",
    "While some optimizations will be handled by LLVM, things like vectorization (coming soon!) can give even further speedups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Grizzly and Real Workloads\n",
    "\n",
    "The workload we looked at above is actually quite simple, so maybe you're not yet impressed with the speedups Weld generated! We hear you! Grizzly is a subset of Pandas that we integrated with Weld. Grizzly allows us to port Pandas workloads over to use Weld, without changing the application!\n",
    "\n",
    "Let's take Grizzly out for a spin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import Pandas and Grizzly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import grizzly.grizzly as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's write a function that loads some data. Note that Grizzly still depends on native Pandas for I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_cleaning_data():\n",
    "    na_values = ['NO CLUE', 'N/A', '0']\n",
    "    requests = pd.read_csv('data/311-service-requests.csv', na_values=na_values, dtype={'Incident Zip': str})\n",
    "    return requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded data in our CSV to a Pandas dataframe, it's time to play! The dataset we just loaded contains a bunch of zipcodes. But like most data our in the wild, it's noisy! :( Let's use Pandas to clean the data!\n",
    "\n",
    "Some of the zipcodes contain more than 5 digits, so we're going to truncate every zipcode to its first 5 digits. In addition, some of the zipcodes are all-zero -- we're going to convert all those zipcodes to `nan`s. After these cleaning operations, we're going to print the unique zipcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_data_cleaning_pandas(requests):\n",
    "    start = time.time()\n",
    "    requests['Incident Zip'] = requests['Incident Zip'].str.slice(0, 5)\n",
    "\n",
    "    # Fix requests with 00000 zipcodes\n",
    "    zero_zips = requests['Incident Zip'] == '00000'\n",
    "    requests['Incident Zip'][zero_zips] = np.nan\n",
    "    \n",
    "    # Display unique zip codes.\n",
    "    result = requests['Incident Zip'].unique()\n",
    "    end = time.time()\n",
    "\n",
    "    print 'Result:', result\n",
    "    print \"End-to-end time: {} seconds\".format(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That wasn't too hard!\n",
    "\n",
    "Now, let's write the same function using Grizzly! Grizzly shares the same API as Pandas, so we're only going to have to wrap the input dataframe in Grizzly's `DataFrameWeld` and we're off to the races!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_data_cleaning_grizzly(requests):\n",
    "    start = time.time()\n",
    "    requests = gr.DataFrameWeld(requests)\n",
    "    requests['Incident Zip'] = requests['Incident Zip'].str.slice(0, 5)\n",
    "    \n",
    "    # Fix requests with 00000 zipcodes\n",
    "    zero_zips = requests['Incident Zip'] == '00000'\n",
    "    requests['Incident Zip'][zero_zips] = 'nan'\n",
    "    \n",
    "    # Display unique zip codes.\n",
    "    result = requests['Incident Zip'].unique().evaluate(verbose=True)\n",
    "    end = time.time()\n",
    "\n",
    "    print 'Result:', result\n",
    "    print \"End-to-end time: {} seconds\".format(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load our data, and call the native Pandas function,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "requests_orig = get_data_cleaning_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: ['11432' '11378' '10032' '10023' '10027' '11372' '11419' '11417' '10011'\n",
      " '11225' '11218' '10003' '10029' '10466' '11219' '10025' '10310' '11236'\n",
      " '10033' '11216' '10016' '10305' '10312' '10026' '10309' '10036' '11433'\n",
      " '11235' '11213' '11379' '11101' '10014' '11231' '11234' '10457' '10459'\n",
      " '10465' '11207' '10002' '10034' '11233' '10453' '10456' '10469' '11374'\n",
      " '11221' '11421' '11215' '10007' '10019' '11205' '11418' '11369' '11249'\n",
      " '10005' '10009' '11211' '11412' '10458' '11229' '10065' '10030' '11222'\n",
      " '10024' '10013' '11420' '11365' '10012' '11214' '11212' '10022' '11232'\n",
      " '11040' '11226' '10281' '11102' '11208' '10001' '10472' '11414' '11223'\n",
      " '10040' '11220' '11373' '11203' '11691' '11356' '10017' '10452' '10280'\n",
      " '11217' '10031' '11201' '11358' '10128' '11423' '10039' '10010' '11209'\n",
      " '10021' '10037' '11413' '11375' '11238' '10473' '11103' '11354' '11361'\n",
      " '11106' '11385' '10463' '10467' '11204' '11237' '11377' '11364' '11434'\n",
      " '11435' '11210' '11228' '11368' '11694' '10464' '11415' '10314' '10301'\n",
      " '10018' '10038' '11105' '11230' '10468' '11104' '10471' '11416' '10075'\n",
      " '11422' '11355' '10028' '10462' '10306' '10461' '11224' '11429' '10035'\n",
      " '11366' '11362' '11206' '10460' '10304' '11360' '11411' '10455' '10475'\n",
      " '10069' '10303' '10308' '10302' '11357' '10470' '11367' '11370' '10454'\n",
      " '10451' '11436' '11426' '10153' '11004' '11428' '11427' '11001' '11363'\n",
      " '10004' '10474' '11430' '10000' '10307' '11239' '10119' '10006' '10048'\n",
      " '11697' '11692' '11693' '10573' '00083' nan '11559' '10020' '77056'\n",
      " '11776' '70711' '10282' '11109' '10044' '02061' '77092' '14225' '55164'\n",
      " '19711' '07306' '90010' '11747' '23541' '11788' '07604' '10112' '11563'\n",
      " '11580' '07087' '11042' '07093' '11501' '92123' '11575' '07109' '11797'\n",
      " '10803' '11716' '11722' '11549' '10162' '23502' '11518' '07020' '08807'\n",
      " '11577' '07114' '11003' '07201' '61702' '10103' '29616' '35209' '11520'\n",
      " '11735' '10129' '11005' '41042' '11590' '06901' '07208' '11530' '13221'\n",
      " '10954' '11111' '10107']\n",
      "End-to-end time: 52.9183762074 seconds\n"
     ]
    }
   ],
   "source": [
    "requests = requests_orig.copy()\n",
    "\n",
    "run_data_cleaning_pandas(requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same thing with Grizzly now. First, let's run Grizzly using just the one thread,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time encoding: 2.14293003082\n",
      "Total time running: 6.07067704201\n",
      "Total time decoding: 0.000344038009644\n",
      "Result: ['11354' '11249' '11797' '00083' '11360' '11361' '19711' '11747' '10020'\n",
      " '11422' '11423' '10022' '35209' '10021' '11101' '10023' '10026' '10025'\n",
      " '11421' '10027' '11426' '11427' '11428' '11363' '11369' '10029' '07604'\n",
      " '23541' '10024' '11420' '11365' '11520' '10128' '11549' '11102' '10129'\n",
      " '11364' '11368' '10028' '11429' '11366' '11362' '11367' '90010' '07109'\n",
      " '07087' '11590' '11433' '11432' '11435' '11434' '11430' '11111' '11436'\n",
      " '07306' '10075' '10153' '11530' '11226' '11225' '11224' '11223' '11518'\n",
      " '11229' '11228' '61702' '11722' '11222' '11221' '11220' '11005' '11004'\n",
      " '11003' '10002' '10001' '10000' '10006' '10005' '10004' '10003' '10803'\n",
      " '10009' '07201' '10007' '10162' '11501' '11001' '11788' '11236' '11237'\n",
      " '11238' '11239' '11232' '11233' '11234' '11235' '92123' '11105' '11106'\n",
      " '11103' '11104' '11109' '11735' '11230' '11231' '07020' '11415' '11414'\n",
      " '11413' '11412' '11411' '11419' '11418' '11417' '11416' '77056' '29616'\n",
      " '02061' '11204' '11203' '11206' '11205' '11208' '11207' '10119' '11209'\n",
      " '11577' '07114' '11694' '11697' '10954' '11691' '11693' '11692' '10303'\n",
      " '10302' '10305' '10304' '10573' '10301' '11201' '10462' '10463' '10460'\n",
      " '10461' '10307' '10306' '10309' '10308' '23502' '10065' '14225' '10069'\n",
      " '10468' '10469' '10466' '10467' '10464' '10465' '11215' '11216' '11213'\n",
      " '11214' '11219' '70711' '11217' '11218' '11370' '11563' '10103' '41042'\n",
      " '07208' '13221' '08807' '10312' '10314' '11211' '11212' '10310' '11210'\n",
      " '10473' '10472' '10471' '10470' '11716' '10034' '10035' '10032' '10033'\n",
      " '10030' '10031' '11379' '10038' '10039' '10036' '10037' '11372' '11374'\n",
      " '11373' 'nan' '11375' '11378' '11377' '10475' '10474' '11559' '10112'\n",
      " '11575' '11580' '11042' '10044' '10040' '55164' '10048' '11040' '11385'\n",
      " '10282' '07093' '10280' '10281' '10107' '06901' '11776' '10010' '10452'\n",
      " '10451' '10454' '10012' '10013' '10455' '10011' '10018' '11357' '10453'\n",
      " '11355' '10456' '10017' '10016' '10014' '11356' '10457' '10459' '77092'\n",
      " '10019' '10458' '11358']\n",
      "End-to-end time: 14.2559411526 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WELD_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "requests = requests_orig.copy()\n",
    "\n",
    "run_data_cleaning_grizzly(requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's kinda cool!\n",
    "\n",
    "What if we increase the number of threads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time encoding: 0.714075088501\n",
      "Total time running: 1.94337296486\n",
      "Total time decoding: 0.000339031219482\n",
      "Result: ['77092' '11249' '11797' '00083' '11360' '11361' '19711' '11747' '10020'\n",
      " '11422' '11423' '10022' '10021' '10024' '11102' '11420' '10025' '10023'\n",
      " '10028' '11367' '11426' '11368' '11428' '10029' '11421' '11427' '11362'\n",
      " '11429' '11101' '11364' '11366' '11365' '10128' '11363' '10026' '11369'\n",
      " '10027' '23541' '07604' '11549' '35209' '11520' '10129' '90010' '07109'\n",
      " '07087' '11590' '11433' '11432' '11435' '11434' '11430' '11111' '11436'\n",
      " '07306' '10075' '11530' '10153' '11226' '11225' '11224' '11223' '11518'\n",
      " '11229' '11228' '61702' '11722' '11222' '11221' '11220' '11005' '11004'\n",
      " '11003' '10002' '10001' '10000' '10006' '10005' '10004' '10003' '10803'\n",
      " '10009' '07201' '10007' '10162' '11501' '11001' '11788' '11236' '11237'\n",
      " '11238' '11239' '11232' '11233' '11234' '11235' '92123' '11105' '11106'\n",
      " '11103' '11104' '11109' '11735' '11230' '11231' '07020' '11415' '11414'\n",
      " '11413' '11412' '11411' '11419' '11418' '11417' '11416' '77056' '29616'\n",
      " '02061' '11204' '11203' '11206' '11205' '11208' '11207' '10119' '11209'\n",
      " '11577' '07114' '11694' '11697' '10954' '11691' '11693' '11692' '10303'\n",
      " '10302' '10305' '10304' '10573' '10301' '11201' '10462' '10463' '10460'\n",
      " '10461' '10307' '10306' '10309' '10308' '23502' '10065' '14225' '10069'\n",
      " '10468' '10469' '10466' '10467' '10464' '10465' '11215' '11216' '11213'\n",
      " '11214' '11219' '10103' '11370' '11218' '11217' '13221' '70711' '07208'\n",
      " '11563' '41042' '08807' '10312' '10314' '11211' '11212' '10310' '11210'\n",
      " '10473' '10472' '10471' '10470' '11716' '10034' '10035' '10032' '10033'\n",
      " '10030' '10031' '11379' '10038' '10039' '10036' '10037' '11372' '11374'\n",
      " '11373' '10112' '11375' '11378' '11377' '10474' '10475' 'nan' '11575'\n",
      " '11559' '11042' '11580' '10044' '10040' '55164' '10048' '11040' '11385'\n",
      " '07093' '10282' '10280' '10281' '10107' '06901' '11776' '10010' '10452'\n",
      " '10451' '10454' '10011' '10013' '10016' '10456' '10455' '11357' '10458'\n",
      " '11355' '10457' '10014' '10012' '10019' '10017' '11354' '10018' '10453'\n",
      " '10459' '11356' '11358']\n",
      "End-to-end time: 8.71040701866 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WELD_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "requests = requests_orig.copy()\n",
    "\n",
    "run_data_cleaning_grizzly(requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad at all!\n",
    "\n",
    "With almost zero change to the application, we were able to get a 5x speedup!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
